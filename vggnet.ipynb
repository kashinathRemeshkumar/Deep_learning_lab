{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a42c2ed-e021-45a4-812e-42ab0bd67289",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 44.9 MiB for an array with shape (47040000,) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapplications\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VGG16\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load MNIST\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m (x_train, y_train), (x_test, y_test) = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmnist\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Resize to 224x224 and convert to RGB\u001b[39;00m\n\u001b[32m      9\u001b[39m x_train = tf.image.resize_with_pad(x_train[..., \u001b[38;5;28;01mNone\u001b[39;00m], \u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python313\\Lib\\site-packages\\keras\\src\\datasets\\mnist.py:68\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     60\u001b[39m path = get_file(\n\u001b[32m     61\u001b[39m     fname=path,\n\u001b[32m     62\u001b[39m     origin=origin_folder + \u001b[33m\"\u001b[39m\u001b[33mmnist.npz\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m     ),\n\u001b[32m     66\u001b[39m )\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m np.load(path, allow_pickle=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     x_train, y_train = \u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx_train\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, f[\u001b[33m\"\u001b[39m\u001b[33my_train\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     69\u001b[39m     x_test, y_test = f[\u001b[33m\"\u001b[39m\u001b[33mx_test\u001b[39m\u001b[33m\"\u001b[39m], f[\u001b[33m\"\u001b[39m\u001b[33my_test\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (x_train, y_train), (x_test, y_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python313\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:254\u001b[39m, in \u001b[36mNpzFile.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m magic == \u001b[38;5;28mformat\u001b[39m.MAGIC_PREFIX:\n\u001b[32m    253\u001b[39m     \u001b[38;5;28mbytes\u001b[39m = \u001b[38;5;28mself\u001b[39m.zip.open(key)\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.zip.read(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python313\\Lib\\site-packages\\numpy\\lib\\format.py:842\u001b[39m, in \u001b[36mread_array\u001b[39m\u001b[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[39m\n\u001b[32m    829\u001b[39m     array = numpy.fromfile(fp, dtype=dtype, count=count)\n\u001b[32m    830\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    831\u001b[39m     \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[32m    832\u001b[39m     \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    840\u001b[39m     \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[32m    841\u001b[39m     \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m     array = \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype.itemsize > \u001b[32m0\u001b[39m:\n\u001b[32m    845\u001b[39m         \u001b[38;5;66;03m# If dtype.itemsize == 0 then there's nothing more to read\u001b[39;00m\n\u001b[32m    846\u001b[39m         max_read_count = BUFFER_SIZE // \u001b[38;5;28mmin\u001b[39m(BUFFER_SIZE, dtype.itemsize)\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 44.9 MiB for an array with shape (47040000,) and data type uint8"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, datasets\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Load MNIST\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "# Resize to 224x224 and convert to RGB\n",
    "x_train = tf.image.resize_with_pad(x_train[..., None], 224, 224)\n",
    "x_test  = tf.image.resize_with_pad(x_test[..., None], 224, 224)\n",
    "x_train = tf.image.grayscale_to_rgb(x_train) / 255.0\n",
    "x_test  = tf.image.grayscale_to_rgb(x_test) / 255.0\n",
    "\n",
    "# Load VGG16 without top classifier\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "base_model.trainable = False  # freeze for transfer learning\n",
    "\n",
    "# Add custom classifier for MNIST\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=3, batch_size=64, validation_split=0.1)\n",
    "print(\"Test accuracy:\", model.evaluate(x_test, y_test)[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
